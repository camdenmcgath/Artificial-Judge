{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camdenmcgath/Artificial-Judge/blob/master/supreme_court_judge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DocZc9NEkdu3",
        "outputId": "f3662763-8638-4ef9-869a-da5ae19bf3f5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.4.0)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.12.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.3)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (8.4.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate transformers seaborn"
      ],
      "id": "DocZc9NEkdu3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "413d74a4-b5b9-442b-b190-14bc8a1b6943"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import transformers as trans\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer, LongformerTokenizer, LongformerForSequenceClassification\n",
        "import torch\n",
        "from torch.optim import AdamW, lr_scheduler\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.interpolate import make_interp_spline, BSpline\n",
        "import nltk\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import Dataset\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "\n",
        "import os\n",
        "import gc\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:2048\"\n"
      ],
      "id": "413d74a4-b5b9-442b-b190-14bc8a1b6943"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90cbf41a-e27f-4ac6-86b2-adae68816503"
      },
      "outputs": [],
      "source": [
        "cases = pd.read_csv(\"justice.csv\")\n",
        "cases.drop(columns=['Unnamed: 0', 'ID', 'name', 'href', 'docket', 'term',  \n",
        "                    'majority_vote', 'minority_vote', 'decision_type', 'disposition', 'issue_area'], inplace=True)\n",
        "cases.dropna(inplace=True)\n"
      ],
      "id": "90cbf41a-e27f-4ac6-86b2-adae68816503"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc06d168-ea68-47e4-b4d9-1b26caf59b41"
      },
      "outputs": [],
      "source": [
        "cases = cases.rename(columns={'first_party_winner': 'winning_party_idx'})\n",
        "for i, row in cases.iterrows():\n",
        "    if row['winning_party_idx'] == True:\n",
        "        cases.loc[i, 'winning_party_idx'] = 0\n",
        "    else:\n",
        "        cases.loc[i, 'winning_party_idx'] = 1"
      ],
      "id": "bc06d168-ea68-47e4-b4d9-1b26caf59b41"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Create a mirrored case for each case, where the parties are swapped to prevent favoring first_party\n",
        "mirrored_cases = cases.copy()\n",
        "mirrored_cases['first_party'], mirrored_cases['second_party'] = mirrored_cases['second_party'], mirrored_cases['first_party']\n",
        "mirrored_cases['winning_party_idx'] = (mirrored_cases['winning_party_idx'] == 0).astype(int)\n",
        "mirrored_cases.reset_index(drop=True, inplace=True)\n",
        "\n",
        "cases = pd.concat([cases, mirrored_cases])\n",
        "cases.reset_index(drop=True, inplace=True)\n",
        "print(f'There are {len(cases)} cases.')\n",
        "print(f'There are {len(cases[cases[\"winning_party_idx\"]==0])} rows for class 0.')\n",
        "print(f'There are {len(cases[cases[\"winning_party_idx\"]==1])} rows for class 1.')"
      ],
      "metadata": {
        "id": "EINhb41ZOId0"
      },
      "id": "EINhb41ZOId0",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae8695c1-f74b-4021-8884-cb0740c8a4a7"
      },
      "outputs": [],
      "source": [
        "cases['facts'] = cases['facts'].str.replace(r'<[^<]+?>', '', regex=True)\n",
        "cases['facts'] = cases['facts'].apply(lambda x: re.sub(r'[^a-zA-Z0-9\\'\\s]', '', x))\n",
        "#cases['facts'] = cases['facts'].str.lower()\n",
        "\n",
        "def word_count(text):\n",
        "  return len(text.split())\n",
        "\n",
        "cases['facts_len'] = cases['facts'].apply(word_count)\n",
        "cases['facts_len'].describe()"
      ],
      "id": "ae8695c1-f74b-4021-8884-cb0740c8a4a7"
    },
    {
      "cell_type": "code",
      "source": [
        "# Create a scatterplot of the fact lengths\n",
        "plt.scatter(range(len(cases['facts_len'])), cases['facts_len'], s=5, alpha=0.5)\n",
        "\n",
        "plt.axhline(y=400, color='red')\n",
        "\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Fact Length')\n",
        "plt.title('Distribution of Fact Lengths')\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# Count the number of facts below 2500 length\n",
        "num_short_facts = len(cases[cases['facts_len'] <= 390])\n",
        "\n",
        "# Calculate the percentage of short facts\n",
        "percentage_short_facts = num_short_facts / len(cases) * 100\n",
        "print(f\"\\nPercentage of cases with fact word no greater than 390: {percentage_short_facts:.2f}%\")"
      ],
      "metadata": {
        "id": "FigKcrhKF2oS"
      },
      "id": "FigKcrhKF2oS",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4fb9678-9e41-4d80-8e4b-abae2b5a1c2f"
      },
      "outputs": [],
      "source": [
        "cases['facts'] = cases.loc[cases['facts_len'] <= 390, 'facts']\n",
        "cases['facts'] = cases.apply(lambda x: f\"{x['first_party']} [SEP] {x['second_party']} [SEP] {x['facts']}\", axis=1)\n",
        "cases = cases.drop(columns=['first_party', 'second_party', 'facts_len'])\n",
        "\n",
        "train_facts, val_facts, train_winners,  val_winners = train_test_split(\n",
        "    cases['facts'], cases['winning_party_idx'], test_size=0.20)\n",
        "\n",
        "train_facts, val_facts = train_facts.tolist(), val_facts.tolist()\n",
        "train_winners, val_winners = [str(i) for i in train_winners], [str(i) for i in val_winners]\n",
        "\n",
        "#leave truncate flag off to ensure that no data is truncated\n",
        "#if data is too large this code will not run\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "train_encodings = tokenizer(train_facts, padding=True)\n",
        "val_encodings = tokenizer(val_facts, padding=True)\n"
      ],
      "id": "b4fb9678-9e41-4d80-8e4b-abae2b5a1c2f"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25705af7-8d9b-4e0f-b779-52f9bb0c07a8"
      },
      "outputs": [],
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(int(self.labels[idx]))\n",
        "        type(item)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = TextDataset(train_encodings, train_winners)\n",
        "val_dataset = TextDataset(val_encodings, val_winners)\n"
      ],
      "id": "25705af7-8d9b-4e0f-b779-52f9bb0c07a8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f1a4bdc-b470-4d01-918d-791995c72336"
      },
      "outputs": [],
      "source": [
        "#Load pretrained model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-cased', \n",
        "                                                      num_labels=2, \n",
        "                                                      hidden_dropout_prob=0.4,\n",
        "                                                      attention_probs_dropout_prob=0.4)\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"test_trainer\", \n",
        "    logging_dir='logs', \n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=32,  \n",
        "    per_device_eval_batch_size=32,\n",
        "    num_train_epochs=3,\n",
        "    logging_steps=50,\n",
        "    learning_rate=1e-6,\n",
        ")\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ],
      "id": "6f1a4bdc-b470-4d01-918d-791995c72336"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18ae0d71-73d2-4d42-bd27-aef72c3a3cd7"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ],
      "id": "18ae0d71-73d2-4d42-bd27-aef72c3a3cd7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "848dad27-ca37-46ae-ae09-193159267ca7"
      },
      "outputs": [],
      "source": [
        "# Evaluate on the validation set\n",
        "result = trainer.evaluate()\n",
        "\n",
        "# Extract the predicted and true labels from the evaluation results\n",
        "y_pred = result.predictions.argmax(axis=1)\n",
        "y_true = result.label_ids\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "id": "848dad27-ca37-46ae-ae09-193159267ca7"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}