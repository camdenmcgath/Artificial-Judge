{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/camdenmcgath/Artificial-Judge/blob/master/supreme_court_judge.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "DocZc9NEkdu3",
        "outputId": "5f383453-7aaa-493e-d7c3-dd56e050da7e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Requirement already satisfied: evaluate in /usr/local/lib/python3.10/dist-packages (0.4.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.28.1)\n",
            "Requirement already satisfied: seaborn in /usr/local/lib/python3.10/dist-packages (0.12.2)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (0.8.10)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.12.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.22.4)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2.27.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate) (4.65.0)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate) (3.2.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (2023.4.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.14.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate) (23.1)\n",
            "Requirement already satisfied: responses<0.19 in /usr/local/lib/python3.10/dist-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.13.3)\n",
            "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /usr/local/lib/python3.10/dist-packages (from seaborn) (3.7.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate) (3.8.4)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.5.0)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate) (2022.7.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (1.26.15)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2022.12.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install evaluate transformers seaborn tabulate"
      ],
      "id": "DocZc9NEkdu3"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1 Gather Necessary Data and Libraries"
      ],
      "metadata": {
        "id": "YnHd8YNQSg47"
      },
      "id": "YnHd8YNQSg47"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "413d74a4-b5b9-442b-b190-14bc8a1b6943"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import re\n",
        "import random\n",
        "from tabulate import tabulate\n",
        "import evaluate\n",
        "import numpy as np\n",
        "import transformers as trans\n",
        "from transformers import BertTokenizer, BertForSequenceClassification, TrainingArguments, Trainer\n",
        "import torch\n",
        "from torch.optim import AdamW, lr_scheduler\n",
        "import torch.nn as nn\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.interpolate import make_interp_spline, BSpline\n",
        "from sklearn.model_selection import train_test_split\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "from tqdm import trange\n",
        "import os\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"max_split_size_mb:2048\"\n"
      ],
      "id": "413d74a4-b5b9-442b-b190-14bc8a1b6943"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "90cbf41a-e27f-4ac6-86b2-adae68816503"
      },
      "outputs": [],
      "source": [
        "cases = pd.read_csv(\"justice.csv\")\n",
        "#drop irrelevant columns\n",
        "cases.drop(columns=['Unnamed: 0', 'ID', 'name', 'href', 'docket', 'term',  \n",
        "                    'majority_vote', 'minority_vote', 'decision_type', 'disposition', 'issue_area'], inplace=True)\n",
        "cases.dropna(inplace=True)\n"
      ],
      "id": "90cbf41a-e27f-4ac6-86b2-adae68816503"
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2 Preprocess Data"
      ],
      "metadata": {
        "id": "ANCKqrf1TPKg"
      },
      "id": "ANCKqrf1TPKg"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.1 Normalization"
      ],
      "metadata": {
        "id": "UFxdY-V1U0ue"
      },
      "id": "UFxdY-V1U0ue"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bc06d168-ea68-47e4-b4d9-1b26caf59b41"
      },
      "outputs": [],
      "source": [
        "#change winner column from boolean to 0 and 1\n",
        "cases = cases.rename(columns={'first_party_winner': 'winning_party_idx'})\n",
        "for i, row in cases.iterrows():\n",
        "    if row['winning_party_idx'] == True:\n",
        "        cases.loc[i, 'winning_party_idx'] = 0\n",
        "    else:\n",
        "        cases.loc[i, 'winning_party_idx'] = 1"
      ],
      "id": "bc06d168-ea68-47e4-b4d9-1b26caf59b41"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Create a mirrored case for each case, where the parties are swapped to prevent favoring first_party"
      ],
      "metadata": {
        "id": "yS6VL4PNU8j0"
      },
      "id": "yS6VL4PNU8j0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EINhb41ZOId0"
      },
      "outputs": [],
      "source": [
        "mirrored_cases = cases.copy()\n",
        "mirrored_cases['first_party'], mirrored_cases['second_party'] = mirrored_cases['second_party'], mirrored_cases['first_party']\n",
        "mirrored_cases['winning_party_idx'] = (mirrored_cases['winning_party_idx'] == 0).astype(int)\n",
        "mirrored_cases.reset_index(drop=True, inplace=True)\n",
        "\n",
        "cases = pd.concat([cases, mirrored_cases])\n",
        "cases.reset_index(drop=True, inplace=True)\n",
        "print(f'There are {len(cases)} cases.')\n",
        "print(f'There are {len(cases[cases[\"winning_party_idx\"]==0])} rows for class 0.')\n",
        "print(f'There are {len(cases[cases[\"winning_party_idx\"]==1])} rows for class 1.')"
      ],
      "id": "EINhb41ZOId0"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In this dataset, text comes with html tags, so begin by removing those tags from the text. Then remove any non-aphanumeric characters. Apsotrophe's were chosen to be left in due to their indication of possessiveness and strong impact in legal semantics. "
      ],
      "metadata": {
        "id": "DWuBueXNVD9b"
      },
      "id": "DWuBueXNVD9b"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ae8695c1-f74b-4021-8884-cb0740c8a4a7"
      },
      "outputs": [],
      "source": [
        "cases['facts'] = cases['facts'].str.replace(r'<[^<]+?>', '', regex=True)\n",
        "cases['facts'] = cases['facts'].str.replace(r'[^a-zA-Z0-9\\']', ' ', regex=True)\n",
        "cases['first_party'] = cases['first_party'].str.replace(r'[^a-zA-Z0-9\\']', ' ', regex=True)\n",
        "cases['second_party'] = cases['second_party'].str.replace(r'[^a-zA-Z0-9\\']', ' ', regex=True)\n",
        "cases['facts'] = cases.apply(lambda x: f\"{x['first_party']} [SEP] {x['second_party']} [SEP] {x['facts']}\", axis=1)"
      ],
      "id": "ae8695c1-f74b-4021-8884-cb0740c8a4a7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Change facts_len from characters to words. This makes predicting the number of tokens more accuracte. "
      ],
      "metadata": {
        "id": "3yjfKcXJT8j3"
      },
      "id": "3yjfKcXJT8j3"
    },
    {
      "cell_type": "code",
      "source": [
        "def word_count(text):\n",
        "  return len(text.split())\n",
        "\n",
        "cases['facts_len'] = cases['facts'].apply(word_count)\n",
        "cases['facts_len'].describe()"
      ],
      "metadata": {
        "id": "ZlkGT_6dSZo2"
      },
      "id": "ZlkGT_6dSZo2",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Visualized the amount of data below 450 which was the threshold deemed to fit under token limit of 512."
      ],
      "metadata": {
        "id": "7xqeSREjUICs"
      },
      "id": "7xqeSREjUICs"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FigKcrhKF2oS"
      },
      "outputs": [],
      "source": [
        "plt.scatter(range(len(cases['facts_len'])), cases['facts_len'], s=5, alpha=0.5)\n",
        "plt.axhline(y=450, color='red')\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Fact Length')\n",
        "plt.title('Distribution of Fact Lengths')\n",
        "plt.show()\n",
        "num_short_facts = len(cases[cases['facts_len'] <= 450])\n",
        "percentage_short_facts = num_short_facts / len(cases) * 100\n",
        "print(f\"\\nPercentage of cases with fact word no greater than 400: {percentage_short_facts:.2f}%\")"
      ],
      "id": "FigKcrhKF2oS"
    },
    {
      "cell_type": "markdown",
      "source": [
        "In order to make sure no data is truncated, we stop word lengths at 450 (max token limit of 512). We want to avoid training BERT on cases with incomplete facts as it may cause BERT to learn relationships and draw incorrect conclusions amongst text features it otherwise would not have. At this point drop all features except the text and label (facts and winner idx)"
      ],
      "metadata": {
        "id": "65lKhc92UXO9"
      },
      "id": "65lKhc92UXO9"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4fb9678-9e41-4d80-8e4b-abae2b5a1c2f"
      },
      "outputs": [],
      "source": [
        "cases = cases[cases['facts_len'] <= 450]\n",
        "print(cases['facts_len'].describe())\n",
        "cases = cases.drop(columns=['first_party', 'second_party', 'facts_len'])"
      ],
      "id": "b4fb9678-9e41-4d80-8e4b-abae2b5a1c2f"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2.2 Tokenization\n",
        "Tokenization code citation: https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894#e7cb"
      ],
      "metadata": {
        "id": "U3YTx_mqVrpl"
      },
      "id": "U3YTx_mqVrpl"
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased', do_lower_case=True)"
      ],
      "metadata": {
        "id": "ISkqPsIpWf_l"
      },
      "id": "ISkqPsIpWf_l",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get a random sample of facts and output the corresponding word tokens and ID's. This helps ensure the tokenizer is woking correctly.\n",
        "\n"
      ],
      "metadata": {
        "id": "lB3IvBZ3V_zM"
      },
      "id": "lB3IvBZ3V_zM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iRncLMhMth0y"
      },
      "outputs": [],
      "source": [
        "text = cases.facts.values\n",
        "labels = cases.winning_party_idx.values\n",
        "print(type(labels))\n",
        "def print_rand_sentence():\n",
        "  '''Displays the tokens and respective IDs of a random text sample'''\n",
        "  index = random.randint(0, len(text)-1)\n",
        "  table = np.array([tokenizer.tokenize(text[index]), \n",
        "                    tokenizer.convert_tokens_to_ids(tokenizer.tokenize(text[index]))]).T\n",
        "  print(tabulate(table,\n",
        "                 headers = ['Tokens', 'Token IDs'],\n",
        "                 tablefmt = 'fancy_grid'))\n",
        "\n",
        "print_rand_sentence()"
      ],
      "id": "iRncLMhMth0y"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Define a preprocessing function to encode input text with the Bert Tokenizer. Create attention masks as well so BEert knows what is relevant and output an example of the encoded tesnor to see padded values (0) and [CLS] 101 and [SEP] 102 tokens. "
      ],
      "metadata": {
        "id": "lI4gq4EZWu4t"
      },
      "id": "lI4gq4EZWu4t"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "E4UFqlCmubr7"
      },
      "outputs": [],
      "source": [
        "token_id = []\n",
        "attention_masks = []\n",
        "\n",
        "def preprocessing(input_text, tokenizer):\n",
        "  '''\n",
        "  Returns <class transformers.tokenization_utils_base.BatchEncoding> with the following fields:\n",
        "    - input_ids: list of token ids\n",
        "    - token_type_ids: list of token type ids\n",
        "    - attention_mask: list of indices (0,1) specifying which tokens should considered by the model (return_attention_mask = True).\n",
        "  '''\n",
        "  return tokenizer.encode_plus(\n",
        "                        input_text,\n",
        "                        add_special_tokens = True,\n",
        "                        max_length = 512,\n",
        "                        pad_to_max_length = True,\n",
        "                        return_attention_mask = True,\n",
        "                        return_tensors = 'pt'\n",
        "                   )\n",
        "\n",
        "\n",
        "for sample in text:\n",
        "  encoding_dict = preprocessing(sample, tokenizer)\n",
        "  token_id.append(encoding_dict['input_ids']) \n",
        "  attention_masks.append(encoding_dict['attention_mask'])\n",
        "\n",
        "\n",
        "token_id = torch.cat(token_id, dim = 0)\n",
        "attention_masks = torch.cat(attention_masks, dim = 0)\n",
        "labels = torch.tensor(labels.astype(np.int64))\n",
        "token_id[6]"
      ],
      "id": "E4UFqlCmubr7"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tes to see if the attention mask is working properly."
      ],
      "metadata": {
        "id": "ARL6_PtJXdcV"
      },
      "id": "ARL6_PtJXdcV"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UZ2Kwr77yt8l"
      },
      "outputs": [],
      "source": [
        "def print_rand_sentence_encoding():\n",
        "  '''Displays tokens, token IDs and attention mask of a random text sample'''\n",
        "  index = random.randint(0, len(text) - 1)\n",
        "  tokens = tokenizer.tokenize(tokenizer.decode(token_id[index]))\n",
        "  token_ids = [i.numpy() for i in token_id[index]]\n",
        "  attention = [i.numpy() for i in attention_masks[index]]\n",
        "\n",
        "  table = np.array([tokens, token_ids, attention]).T\n",
        "  print(tabulate(table, \n",
        "                 headers = ['Tokens', 'Token IDs', 'Attention Mask'],\n",
        "                 tablefmt = 'fancy_grid'))\n",
        "\n",
        "print_rand_sentence_encoding()"
      ],
      "id": "UZ2Kwr77yt8l"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Split 80% training and 20% validation indices, and pss the respective indices in to the TensorDataset with the token ids, attention masks and labels. \n",
        "\n"
      ],
      "metadata": {
        "id": "xEcJFDOwXl7d"
      },
      "id": "xEcJFDOwXl7d"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CmJyFQGW0V3u"
      },
      "outputs": [],
      "source": [
        "train_idx, val_idx = train_test_split(\n",
        "  np.arange(len(labels)),\n",
        "  test_size=0.2,\n",
        "  shuffle=True,\n",
        "  stratify=labels   \n",
        ")"
      ],
      "id": "CmJyFQGW0V3u"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wdzcd7Y22iu"
      },
      "outputs": [],
      "source": [
        "# Train and validation sets\n",
        "train_dataset = TensorDataset(token_id[train_idx], \n",
        "                          attention_masks[train_idx], \n",
        "                          labels[train_idx])\n",
        "\n",
        "val_dataset = TensorDataset(token_id[val_idx], \n",
        "                        attention_masks[val_idx], \n",
        "                        labels[val_idx])"
      ],
      "id": "0wdzcd7Y22iu"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3 Models"
      ],
      "metadata": {
        "id": "bMXK6IQ8YNDb"
      },
      "id": "bMXK6IQ8YNDb"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Vanilla Pytorch\n",
        "Much thanks again to Nicolo Cosmio Albanese for the vanilla Pytroch implementation: https://towardsdatascience.com/fine-tuning-bert-for-text-classification-54e7df642894#e7cb"
      ],
      "metadata": {
        "id": "UAbSf_GOYVjv"
      },
      "id": "UAbSf_GOYVjv"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 Dataloaders and Other Initializations"
      ],
      "metadata": {
        "id": "TQzWr-eyZX4X"
      },
      "id": "TQzWr-eyZX4X"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8fCH4-nd5Jm8"
      },
      "outputs": [],
      "source": [
        "# Prepare DataLoader\n",
        "train_dataloader = DataLoader(\n",
        "            train_dataset,\n",
        "            sampler = RandomSampler(train_dataset),\n",
        "            batch_size = 16\n",
        "        )\n",
        "\n",
        "validation_dataloader = DataLoader(\n",
        "            val_dataset,\n",
        "            sampler = SequentialSampler(val_dataset),\n",
        "            batch_size = 16\n",
        "        )"
      ],
      "id": "8fCH4-nd5Jm8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yBphoA3Q4U60"
      },
      "outputs": [],
      "source": [
        "# Load the BertForSequenceClassification model\n",
        "model = BertForSequenceClassification.from_pretrained(\n",
        "    'bert-large-uncased',\n",
        "    num_labels = 2,\n",
        "    output_attentions = False,\n",
        "    output_hidden_states = False,\n",
        ")\n",
        "\n",
        "# Recommended learning rates (Adam): 5e-5, 3e-5, 2e-5. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "optimizer = torch.optim.AdamW(model.parameters(), \n",
        "                              lr = 5e-5,\n",
        "                              eps = 1e-08\n",
        "                              )\n",
        "\n",
        "# Run on GPU\n",
        "model.cuda()"
      ],
      "id": "yBphoA3Q4U60"
    },
    {
      "cell_type": "markdown",
      "source": [
        "Functions to calculate accuracies when validating the model"
      ],
      "metadata": {
        "id": "86rMnKT6Yyln"
      },
      "id": "86rMnKT6Yyln"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQ1q1FWb47t4"
      },
      "outputs": [],
      "source": [
        "def b_tp(preds, labels):\n",
        "  '''Returns True Positives (TP): count of correct predictions of actual class 1'''\n",
        "  return sum([preds == labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fp(preds, labels):\n",
        "  '''Returns False Positives (FP): count of wrong predictions of actual class 1'''\n",
        "  return sum([preds != labels and preds == 1 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_tn(preds, labels):\n",
        "  '''Returns True Negatives (TN): count of correct predictions of actual class 0'''\n",
        "  return sum([preds == labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_fn(preds, labels):\n",
        "  '''Returns False Negatives (FN): count of wrong predictions of actual class 0'''\n",
        "  return sum([preds != labels and preds == 0 for preds, labels in zip(preds, labels)])\n",
        "\n",
        "def b_metrics(preds, labels):\n",
        "  '''\n",
        "  Returns the following metrics:\n",
        "    - accuracy    = (TP + TN) / N\n",
        "    - precision   = TP / (TP + FP)\n",
        "    - recall      = TP / (TP + FN)\n",
        "    - specificity = TN / (TN + FP)\n",
        "  '''\n",
        "  preds = np.argmax(preds, axis = 1).flatten()\n",
        "  labels = labels.flatten()\n",
        "  tp = b_tp(preds, labels)\n",
        "  tn = b_tn(preds, labels)\n",
        "  fp = b_fp(preds, labels)\n",
        "  fn = b_fn(preds, labels)\n",
        "  b_accuracy = (tp + tn) / len(labels)\n",
        "  b_precision = tp / (tp + fp) if (tp + fp) > 0 else 'nan'\n",
        "  b_recall = tp / (tp + fn) if (tp + fn) > 0 else 'nan'\n",
        "  b_specificity = tn / (tn + fp) if (tn + fp) > 0 else 'nan'\n",
        "  return b_accuracy, b_precision, b_recall, b_specificity"
      ],
      "id": "BQ1q1FWb47t4"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.2 Pytorch Manual Training Loop"
      ],
      "metadata": {
        "id": "Q1myRC7oZOTN"
      },
      "id": "Q1myRC7oZOTN"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eXD3i7Gz4ZHz"
      },
      "outputs": [],
      "source": [
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Recommended number of epochs: 2, 3, 4. See: https://arxiv.org/pdf/1810.04805.pdf\n",
        "epochs = 5\n",
        "\n",
        "for _ in trange(epochs, desc = 'Epoch'):\n",
        "    \n",
        "    # ========== Training ==========\n",
        "    \n",
        "    # Set model to training mode\n",
        "    model.train()\n",
        "    \n",
        "    # Tracking variables\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        optimizer.zero_grad()\n",
        "        # Forward pass\n",
        "        train_output = model(b_input_ids, \n",
        "                             token_type_ids = None, \n",
        "                             attention_mask = b_input_mask, \n",
        "                             labels = b_labels)\n",
        "        # Backward pass\n",
        "        train_output.loss.backward()\n",
        "        optimizer.step()\n",
        "        # Update tracking variables\n",
        "        tr_loss += train_output.loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "\n",
        "    # ========== Validation ==========\n",
        "\n",
        "    # Set model to evaluation mode\n",
        "    model.eval()\n",
        "\n",
        "    # Tracking variables \n",
        "    val_accuracy = []\n",
        "    val_precision = []\n",
        "    val_recall = []\n",
        "    val_specificity = []\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():\n",
        "          # Forward pass\n",
        "          eval_output = model(b_input_ids, \n",
        "                              token_type_ids = None, \n",
        "                              attention_mask = b_input_mask)\n",
        "        logits = eval_output.logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()\n",
        "        # Calculate validation metrics\n",
        "        b_accuracy, b_precision, b_recall, b_specificity = b_metrics(logits, label_ids)\n",
        "        val_accuracy.append(b_accuracy)\n",
        "        # Update precision only when (tp + fp) !=0; ignore nan\n",
        "        if b_precision != 'nan': val_precision.append(b_precision)\n",
        "        # Update recall only when (tp + fn) !=0; ignore nan\n",
        "        if b_recall != 'nan': val_recall.append(b_recall)\n",
        "        # Update specificity only when (tn + fp) !=0; ignore nan\n",
        "        if b_specificity != 'nan': val_specificity.append(b_specificity)\n",
        "\n",
        "    print('\\n\\t - Train loss: {:.4f}'.format(tr_loss / nb_tr_steps))\n",
        "    print('\\t - Validation Accuracy: {:.4f}'.format(sum(val_accuracy)/len(val_accuracy)))\n",
        "    print('\\t - Validation Precision: {:.4f}'.format(sum(val_precision)/len(val_precision)) if len(val_precision)>0 else '\\t - Validation Precision: NaN')\n",
        "    print('\\t - Validation Recall: {:.4f}'.format(sum(val_recall)/len(val_recall)) if len(val_recall)>0 else '\\t - Validation Recall: NaN')\n",
        "    print('\\t - Validation Specificity: {:.4f}\\n'.format(sum(val_specificity)/len(val_specificity)) if len(val_specificity)>0 else '\\t - Validation Specificity: NaN')\n"
      ],
      "id": "eXD3i7Gz4ZHz"
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 Huggingface's Transformers Trainer Method\n",
        "Anther approach to the one done above on the same preprocessed data. Results should come out the same"
      ],
      "metadata": {
        "id": "NctSoNMPZ3jF"
      },
      "id": "NctSoNMPZ3jF"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Resplitting Training and Validation Data"
      ],
      "metadata": {
        "id": "BgWQHTedaXv3"
      },
      "id": "BgWQHTedaXv3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z_8ebNQi0-bN"
      },
      "outputs": [],
      "source": [
        "train_facts, val_facts, train_winners,  val_winners = train_test_split(\n",
        "    cases['facts'], cases['winning_party_idx'], test_size=0.2, random_state=42)\n",
        "\n",
        "def describe_facts(txt_df):\n",
        "  txt_df2 = txt_df.copy()\n",
        "  txt_df2['word_count'] = txt_df.apply(word_count)\n",
        "  print(txt_df2['word_count'].describe())\n",
        "\n",
        "#ensure train/test data has similar text size distribution\n",
        "describe_facts(train_facts)\n",
        "describe_facts(val_facts)\n",
        "print(train_winners.describe())\n",
        "print(val_winners.describe())"
      ],
      "id": "Z_8ebNQi0-bN"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2 Re-encoding Using Custom Dataset"
      ],
      "metadata": {
        "id": "36_sjqtGadw0"
      },
      "id": "36_sjqtGadw0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "S_vuETg8teQF"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_facts, val_facts = train_facts.tolist(), val_facts.tolist()\n",
        "train_winners, val_winners = [str(i) for i in train_winners], [str(i) for i in val_winners]\n",
        "\n",
        "train_encodings = tokenizer(train_facts, padding=True)\n",
        "val_encodings = tokenizer(val_facts, padding=True)"
      ],
      "id": "S_vuETg8teQF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "25705af7-8d9b-4e0f-b779-52f9bb0c07a8"
      },
      "outputs": [],
      "source": [
        "class TextDataset(torch.utils.data.Dataset):\n",
        "    def __init__(self, encodings, labels):\n",
        "        self.encodings = encodings\n",
        "        self.labels = labels\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n",
        "        item['labels'] = torch.tensor(int(self.labels[idx]))\n",
        "        type(item)\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "train_dataset = TextDataset(train_encodings, train_winners)\n",
        "val_dataset = TextDataset(val_encodings, val_winners)\n"
      ],
      "id": "25705af7-8d9b-4e0f-b779-52f9bb0c07a8"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.3 Fine Tune"
      ],
      "metadata": {
        "id": "UjWvy1NUar_B"
      },
      "id": "UjWvy1NUar_B"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6f1a4bdc-b470-4d01-918d-791995c72336"
      },
      "outputs": [],
      "source": [
        "#Load pretrained model\n",
        "model = BertForSequenceClassification.from_pretrained('bert-base-uncased', \n",
        "                                                      num_labels=2, \n",
        "                                                      #hidden_dropout_prob=0.4,\n",
        "                                                      #attention_probs_dropout_prob=0.4\n",
        "                                                      )\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"test_trainer\", \n",
        "    logging_dir='logs', \n",
        "    evaluation_strategy=\"epoch\",\n",
        "    per_device_train_batch_size=16,  \n",
        "    per_device_eval_batch_size=16,\n",
        "    num_train_epochs=4,\n",
        "    gradient_accumulation_steps=1,\n",
        "    learning_rate=5e-5,\n",
        "    logging_steps=50,\n",
        ")\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "def compute_metrics(eval_pred):\n",
        "    logits, labels = eval_pred\n",
        "    predictions = np.argmax(logits, axis=1)\n",
        "    return metric.compute(predictions=predictions, references=labels)\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=val_dataset,\n",
        "    compute_metrics=compute_metrics,\n",
        ")\n"
      ],
      "id": "6f1a4bdc-b470-4d01-918d-791995c72336"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.4 Train"
      ],
      "metadata": {
        "id": "xjZEfSHDax8S"
      },
      "id": "xjZEfSHDax8S"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "18ae0d71-73d2-4d42-bd27-aef72c3a3cd7"
      },
      "outputs": [],
      "source": [
        "trainer.train()"
      ],
      "id": "18ae0d71-73d2-4d42-bd27-aef72c3a3cd7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "848dad27-ca37-46ae-ae09-193159267ca7"
      },
      "outputs": [],
      "source": [
        "# Evaluate on the validation set\n",
        "result = trainer.predict(val_dataset)\n",
        "\n",
        "# Extract the predicted and true labels from the evaluation results\n",
        "y_pred = result.predictions.argmax(axis=1)\n",
        "y_true = result.label_ids\n",
        "\n",
        "# Compute the confusion matrix\n",
        "cm = confusion_matrix(y_true, y_pred)\n",
        "\n",
        "# Plot the confusion matrix as a heatmap\n",
        "sns.heatmap(cm, annot=True, cmap='Blues', fmt='g')\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('True')\n",
        "plt.title('Confusion Matrix')\n",
        "plt.show()"
      ],
      "id": "848dad27-ca37-46ae-ae09-193159267ca7"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "gpuClass": "premium",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}